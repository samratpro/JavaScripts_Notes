## First: Install required dependencies
```bash
npm install csv-parser csv-writer
npm install --save-dev @types/node
npm install csv-stringify # lightweight built-in + popular libraries:
```
## Text File Operations (.txt)
```ts
// Modern, clean imports (no * as anywhere)
import fs from 'fs/promises';
import path from 'path';

// Ensure directory exists
async function ensureDir(filePath: string): Promise<void> {
  await fs.mkdir(path.dirname(filePath), { recursive: true });
}

// Write (overwrite) a text file
export async function writeTextFile(filePath: string, content: string): Promise<void> {
  await ensureDir(filePath);
  await fs.writeFile(filePath, content, 'utf-8');
}

// Append to a text file (adds newline automatically)
export async function appendTextFile(filePath: string, content: string): Promise<void> {
  await ensureDir(filePath);
  await fs.appendFile(filePath, content + '\n', 'utf-8');
}

// Read entire text file as string
export async function readTextFile(filePath: string): Promise<string> {
  return await fs.readFile(filePath, 'utf-8');
}

// Read file line by line (proper streaming version – much better for large files)
export async function readTextFileLines(filePath: string): AsyncIterable<string> {
  const fileHandle = await fs.open(filePath, 'r');
  const stream = fileHandle.createReadStream({ encoding: 'utf-8' });

  let buffer = '';
  for await (const chunk of stream) {
    buffer += chunk;
    let lineEnd: number;
    while ((lineEnd = buffer.indexOf('\n')) !== -1) {
      let line = buffer.slice(0, lineEnd);
      buffer = buffer.slice(lineEnd + 1);
      // Handle Windows CRLF
      if (line.endsWith('\r')) line = line.slice(0, -1);
      if (line.trim() !== '') yield line;
    }
  }

  // Yield remaining line if file doesn't end with newline
  if (buffer.trim() !== '') yield buffer.trim();

  await fileHandle.close();
}
```

## Write CSV (create or overwrite)
```ts
// csv-stringify-modern-example.ts
import fs from 'fs/promises';
import path from 'path';
import { stringify } from 'csv-stringify/sync';


const ensureDir = async (filePath: string): Promise<void> => {
  await fs.mkdir(path.dirname(filePath), { recursive: true });
};

export async function writeCsvFile<T extends Record<string, any>>(
  filePath: string,
  records: T[],
  header: { id: keyof T; title: string }[]
): Promise<void> {
  await ensureDir(filePath);

  const columns = header.map(h => ({
    key: h.id as string,
    header: h.title,
  }));

  const csvContent = stringify(records, {
    header: true,
    columns,
  });
  await fs.writeFile(filePath, csvContent, 'utf-8');
}

// ─────────────────────────────────────
// EXACT SAME EXAMPLE 
interface Person {
  name: string;
  age: number;
  city: string;
}

const header = [
  { id: 'name', title: 'Full Name' },
  { id: 'age', title: 'Age' },
  { id: 'city', title: 'City' },
] as const;

const peopleRecords: Person[] = [
  { name: 'Alice Johnson', age: 28, city: 'Paris' },
  { name: 'Bob Smith', age: 35, city: 'London' },
];

// Run it! — IDENTICAL TO BEFORE
async function main() {
  await writeCsvFile('./output/people.csv', peopleRecords, header);
  console.log('CSV created → ./output/people.csv');
}

main().catch(console.error);
```
## Append to existing CSV
```ts
// append-csv-stringify-modern.ts
import fs from 'fs/promises';
import path from 'path';
import { stringify } from 'csv-stringify/sync';

const ensureDir = async (filePath: string): Promise<void> => {
  await fs.mkdir(path.dirname(filePath), { recursive: true });
};

// YOUR APPEND FUNCTION —10× FASTER
export async function appendToCsvFile<T extends Record<string, any>>(
  filePath: string,
  records: T[],
  header: { id: keyof T; title: string }[]
): Promise<void> {
  await ensureDir(filePath);

  // Detect if file exists → only write header on first run
  const fileExists = await fs.stat(filePath).then(() => true).catch(() => false);

  const columns = header.map(h => ({
    key: h.id as string,
    header: h.title,
  }));

  const csvContent = stringify(records, {
    header: !fileExists,  // Only write header if file is new
    columns,
  });

  // Append mode using appendFile
  await fs.appendFile(filePath, csvContent, 'utf-8');
}

// ─────────────────────────────────────
// EXACT SAME EXAMPLE 
interface Product {
  title: string;
  price: string;
  url: string;
  scrapedAt: string;
}

// Define header once (reuse everywhere) — IDENTICAL
const header = [
  { id: 'title', title: 'Product Name' },
  { id: 'price', title: 'Price' },
  { id: 'url', title: 'Link' },
  { id: 'scrapedAt', title: 'Scraped At' },
] as const;

// Fake data — IDENTICAL
const fakeScrapedItems: Product[] = [
  { title: 'iPhone 16', price: '$999', url: 'https://apple.com/1', scrapedAt: new Date().toISOString() },
  { title: 'MacBook Pro', price: '$2399', url: 'https://apple.com/2', scrapedAt: new Date().toISOString() },
  { title: 'AirPods Max', price: '$549', url: 'https://apple.com/3', scrapedAt: new Date().toISOString() },
  { title: 'Samsung S24', price: '$899', url: 'https://samsung.com/1', scrapedAt: new Date().toISOString() },
];

// Main function — 100% IDENTICAL
async function main() {
  const filePath = './output/scraped-products.csv';

  console.log('Starting append loop...');

  for (const item of fakeScrapedItems) {
    await appendToCsvFile(filePath, [item], header);
    console.log(`Appended: ${item.title}`);
    
    await new Promise(r => setTimeout(r, 300));
  }

  console.log(`\nDone! All items saved to:\n${path.resolve(filePath)}`);
}

main().catch(console.error);
```
## Read CSV File
```ts
// read-csv-modern-csv-parse.ts
import { createReadStream } from 'fs';
import { parse } from 'csv-parse';
import { pipeline } from 'stream/promises';
import { promisify } from 'util';
import { finished } from 'stream';

// Modern csv-parse (replaces csv-parser)
const parseStream = parse({
  columns: true,        // Automatically use first row as headers
  skip_empty_lines: true,
  trim: true,
});

export const readCsvFile = async <T = any>(filePath: string): Promise<T[]> => {
  return new Promise<T[]>((resolve, reject) => {
    if (!require('fs').existsSync(filePath)) {
      return resolve([]);
    }

    const results: T[] = [];

    pipeline(
      createReadStream(filePath),
      parseStream,
      async function* (source) {
        for await (const row of source) {
          results.push(row as T);
        }
      },
      (err) => {
        if (err) reject(err);
        else resolve(results);
      }
    );
  });
};

// ─────────────────────────────────────
// EXACT SAME EXAMPLE 
interface Person {
  name: string;
  age: string;
  city: string;
}

async function main() {
  const filePath = './output/people.csv';

  // Read the CSV — typed array!
  const people = await readCsvFile<Person>(filePath);

  if (people.length === 0) {
    console.log('No data found or file missing');
    return;
  }

  console.log(`Found ${people.length} people:\n`);

  // Simple loop — IDENTICAL
  for (const [i, person] of people.entries()) {
    console.log(`${i + 1}. ${person.name} – ${person.age} years old – ${person.city}`);
  }

  // Or even shorter with for...of
  // for (const p of people) {
  //   console.log(`→ ${p.name} from ${p.city}`);
  // }
}

main().catch(console.error);
```

## Handle JSON file
```ts
// json-utils.ts
import fs from 'fs/promises';
import path from 'path';

// Ensure directory exists (shared helper)
const ensureDir = async (filePath: string): Promise<void> => {
  await fs.mkdir(path.dirname(filePath), { recursive: true });
};

// ──────────────────────────────────────────────────────────────
// 1. Read JSON file (with fallback to default)
export async function readJson<T>(filePath: string, defaultValue: T): Promise<T> {
  try {
    const data = await fs.readFile(filePath, 'utf-8');
    return JSON.parse(data) as T;
  } catch (err: any) {
    if (err.code === 'ENOENT') {
      console.log(`File not found → returning default: ${filePath}`);
      return defaultValue;
    }
    throw err;
  }
}

// ──────────────────────────────────────────────────────────────
// 2. Write / Overwrite JSON (pretty printed)
export async function writeJson<T>(filePath: string, data: T): Promise<void> {
  await ensureDir(filePath);
  await fs.writeFile(filePath, JSON.stringify(data, null, 2), 'utf-8');
}

// ──────────────────────────────────────────────────────────────
// 3. Append to JSON Array (most common in scrapers!)
export async function appendJsonArray<T>(
  filePath: string,
  newItem: T
): Promise<void> {
  const array = await readJson<T[]>(filePath, []);
  array.push(newItem);
  await writeJson(filePath, array);
}

// ──────────────────────────────────────────────────────────────
// 4. Update JSON object (e.g. progress, config, metadata)
export async function updateJson<T extends Record<string, any>>(
  filePath: string,
  updater: (current: T) => T,
  defaultValue: T
): Promise<void> {
  const current = await readJson(filePath, defaultValue);
  const updated = updater(current);
  await writeJson(filePath, updated);
}


// example-usage.ts
import { readJson, writeJson, appendJsonArray, updateJson } from './json-utils';

interface Product {
  title: string;
  price: string;
  url: string;
  scrapedAt: string;
}

const PRODUCTS_FILE = 'data/products.json';
const PROGRESS_FILE = 'data/scrape-progress.json';

// Fake data
const fakeProducts: Product[] = [
  { title: "iPhone 16", price: "$999", url: "https://apple.com/1", scrapedAt: new Date().toISOString() },
  { title: "AirPods Pro", price: "$249", url: "https://apple.com/2", scrapedAt: new Date().toISOString() },
];

// ─────────────────────────────────────
// 1. Save scraped items one by one (append mode)
async function scrapeAndAppend() {
  console.log("Scraping and appending one by one...");
  for (const product of fakeProducts) {
    await appendJsonArray(PRODUCTS_FILE, product);
    console.log(`Appended: ${product.title}`);
    // await delay(500); // simulate network
  }
}

// ─────────────────────────────────────
// 2. Track scraping progress (resume support!)
async function markProgress(page: number) {
  await updateJson(PROGRESS_FILE, (prev) => ({
    lastPage: page,
    totalProcessed: (prev.totalProcessed || 0) + 1,
    resumed: prev.resumed || false,
    lastRun: new Date().toISOString(),
  }), { lastPage: 0, totalProcessed: 0 });
}

// ─────────────────────────────────────
// 3. Read and show all saved data
async function showAll() {
  const products = await readJson<Product[]>(PRODUCTS_FILE, []);
  console.log(`\nFound ${products.length} products:`);
  console.table(products.map(p => ({ title: p.title, price: p.price })));

  const progress = await readJson(PROGRESS_FILE, { lastPage: 0 });
  console.log("Progress:", progress);
}

// ─────────────────────────────────────
// Run everything
async function main() {
  await scrapeAndAppend();
  await markProgress(42);
  await showAll();

  // Example: Force resume from page 201 next time
  await writeJson(PROGRESS_FILE, { lastPage: 200, totalProcessed: 1000, resumed: true });
  console.log("Forced next run to resume from page 201");
}

main().catch(console.error);
```

