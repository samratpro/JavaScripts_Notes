# Cheerio – Complete TypeScript Techniques

A TypeScript-focused reference for DOM parsing & data extraction using Cheerio. Includes selector patterns, traversal, common extraction templates, real-world scrapers, and integration with got.

## Why Cheerio?
- jQuery-like syntax for server-side parsing
- Fast and lightweight (no browser required)
- Ideal for static HTML scraping
- Works great with got for HTTP + parsing workflows

## Installation

```bash
npm install cheerio
# TypeScript types are included
```

## Load HTML (TypeScript)

```ts
import cheerio from 'cheerio';
import got from 'got';

const html = await got('https://example.com').text();
const $ = cheerio.load(html);
```

## Core Principle
Inside .each() callbacks, always re-wrap raw elements with $(el) or use $(this):

```ts
$('.item').each((i, el) => {
  const $el = $(el); // re-wrap
  console.log($el.find('.price').text());
});
```

## Basic Selectors
```ts
- $('h1') — all h1 tags
- $('.price') — by class
- $('#main') — by id
- $('[data-id]') — any element with attribute
- $('[href*="login"]') — contains substring
- $('[src$=".jpg"]') — ends with
- $('[data-index^="10"]') — starts with
- $('div[class="name"]')
- $('selector').eq(5)  // 5th index, but 6th number
- $('div.bi-ctas').eq(2).find('div.number-contact')  // traverse like xpath
- $('div[data-asin] h2 a').text()        // traverse like xpath `` //div[@data-asin]//h2//a ``
-  $('').attr('href') // get attribute 
```
## Pro-Level: Most Useful Attribute Patterns
```ts
// 1. Any element with a specific data-* attribute (exists)
$('[data-product-id]')           // like //*[@data-product-id]

// 2. Exact match
$('[data-role="navigation"]')    // = //*[@data-role="navigation"]

// 3. Contains (most common for dynamic classes/ids)
$('[class*="product-card"]')     // contains "product-card"
$('[href*="amazon.com"]')        
$('[data-asin*="B0"]')           // Amazon ASIN starts with B0

// 4. Starts with
$('[id^="post-"]')               // id starts with "post-"
$('[data-lazy-src^="https://"]') // lazy images

// 5. Ends with
$('[src$=".webp"]')
$('[href$=".pdf"]')

// 6. Multiple attributes (AND condition)
$('a[href][title]')                        // has both href and title
$('img[src][alt*="logo"]')                 // has src + alt contains "logo"
$('div[data-price][data-discount]')        // has both data attributes

// 7. Attribute + tag name (exactly like XPath)
//div[@class="error"]  →  $('div.error') or $('div[class="error"]')

// 8. Case-insensitive match (rare but useful)
$('[href*="Login" i]')         // Note: not all Cheerio versions support "i" flag
// Better: use .filter()
$('a').filter((i, el) => /login/i.test($(el).attr('href') || ''))

// index validation
const fifthNumber = $('div.number-contact').eq(4);
if (fifthNumber.length) {
  console.log(fifthNumber.text().trim());
} else {
  console.log('Less than 5 elements found');
}
$('div.bi-ctas').eq(2).find('div.number-contact')  // traverse like xpath
$('div[data-asin] h2 a').text()        // traverse like xpath `` //div[@data-asin]//h2//a ``
```
## Real-World Scraping Examples
```ts
// Amazon product (common dynamic classes)
$('div[data-asin]')                              // all products
$('div[data-asin] h2 a').text()                  // title
$('div[data-asin] img').attr('src')              // image

// Shopify / any lazy-load site
$('img[data-src]')                               // lazy images
$('img').map((i,el) => $(el).attr('src') || $(el).attr('data-src')).get()

// Find "Add to Cart" button (any tag)
$('[data-add-to-cart], [name="add"], [id*="add"], [class*="add"]')

// Find pagination "Next" button (by text + attribute)
$('a').filter((i, el) => 
  $(el).text().trim() === 'Next' && $(el).attr('href')
)

// Find all elements with JSON in data-* attribute
$('[data-props], [data-json], [data-config]').each((i, el) => {
  const jsonStr = $(el).attr('data-props') || $(el).html();
  try { console.log(JSON.parse(jsonStr)); } catch {}
})
```

## Traversing (Most Used)
```ts
- $(el).find('.price') — deep search (most common)
- $(el).children('a') — direct children only
- $(el).parent() — one level up
- $(el).parents('.container') — ancestor
- $(el).next() / .prev() — sibling
- $(el).siblings() — all siblings
- $(el).eq(2) — nth item (0-based)
- .first() / .last() — boundaries
- .slice(0, 10) — range
```

## Real Extraction Patterns (TypeScript-ready)

All examples assume you have `const $ = cheerio.load(html);`

Pattern 1 — Product Cards (Amazon/Shopify style)

```ts
interface Product {
  title: string;
  price: string;
  url: string;
  image: string;
}

const products: Product[] = $('.product-card').map((i, el) => {
  const $card = $(el);
  return {
    title: $card.find('h2 a').text().trim(),
    price: $card.find('.price').text().replace(/[^0-9.]/g, ''),
    url: new URL($card.find('a').attr('href') || '', 'https://example.com').href,
    image: $card.find('img').attr('src') || $card.find('img').data('src') || 'N/A'
  };
}).get();
```

Pattern 2 — Table to JSON

```ts
const rows = $('table tr').slice(1).map((i, row) => ({
  rank: $(row).find('td').eq(0).text().trim(),
  name: $(row).find('td').eq(1).text().trim(),
  score: parseInt($(row).find('td').eq(2).text()) || 0
})).get();
```

Pattern 3 — Extract JSON from script[type="application/ld+json"]

```ts
const rawJson = $('script[type="application/ld+json"]').first().html();
if (rawJson) {
  try {
    const data = JSON.parse(rawJson);
    // data typed as unknown — cast or validate
    console.log(data);
  } catch (err) {
    console.warn('JSON parse error', err);
  }
}
```

Pattern 4 — Hacker News / Reddit style (two-row items)

```ts
$('.athing').each((i, el) => {
  const $item = $(el);
  const $subline = $item.next();
  const title = $item.find('.titleline a').text();
  const points = parseInt($subline.find('.score').text()) || 0;
  const comments = parseInt($subline.find('a').last().text()) || 0;
  console.log({ title, points, comments });
});
```

Pattern 5 — Get links with text filter

```ts
const nextHref = $('a').filter((i, el) => $(el).text().trim() === 'Next →').attr('href');
```

Pattern 6 — Nested Data (comments)

```ts
const comments = $('.comment').map((i, el) => {
  const $c = $(el);
  return {
    author: $c.find('.author').text().trim(),
    date: $c.find('.date').attr('title'),
    text: $c.find('.text').text().trim(),
    replies: $c.find('.reply').length
  };
}).get();
```

Pattern 7 — Attribute fallbacks (images)

```ts
const src = $img.attr('src') || $img.attr('data-src') || $img.attr('data-lazy-src') || 'default.jpg';
```

Pattern 8 — Clean & parse numbers

```ts
const price = $(el).text().match(/[\d.]+/)?.[0] ?? null;
const discount = parseInt($(el).text().match(/(\d+)%/)?.[1] ?? '0') || 0;
```

Pattern 9 — Meta tags (OpenGraph)

```ts
const ogTitle = $('meta[property="og:title"]').attr('content');
const ogImage = $('meta[property="og:image"]').attr('content');
const desc = $('meta[name="description"]').attr('content');
```

Pattern 10 — Remove noise & extract main content

```ts
$('script, style, noscript, svg, iframe').remove();
const content = $('body').text().trim().replace(/\s+/g, ' ');
```

## Text & Attribute Pro Tips
```
- Clean text: .text().trim().replace(/\s+/g, ' ')
- Extract number: .text().match(/[\d.]+/)?.[0]
- data-* attributes: $(el).data('asin')
- Make absolute URL: new URL($('a').attr('href') || '', 'https://example.com').href
- Check exist: if ($('.element').length) { /* found */ }
- Get outer HTML: $.html(el)
- Clone nodes: const $clone = $(el).clone();
```

## Common Bugs & Fixes

Wrong:
```ts
$('.item').each((i, el) => {
  el.find('.price').text(); // ❌ el is raw DOM, not re-wrapped
});
```

Correct:
```ts
$('.item').each((i, el) => {
  const $el = $(el); // ✅ re-wrap
  $el.find('.price').text();
});
```

Or use function form where this is wrapped:
```ts
$('.item').each(function () {
  const $this = $(this); // already wrapped
  $this.find('.price').text();
});
```

## One-liner Magic
```ts
- $('meta[property="og:title"]').attr('content') — OpenGraph title
- $('h1, .title, title').first().text().trim() — main title
- $('a:contains("Next")').attr('href') — next page
- $('.current').parent().next().find('a').attr('href') — pagination
- $('img').map((i,el) => $(el).attr('src')).get() — all images
- $('.price').text().replace(/[^0-9.]/g, '') — extract numbers
```

## Cheerio API Cheat Sheet
```ts
- .find(selector) — descendants
- .children(selector) — direct children
- .parent() — parent
- .next() / .prev() — siblings
- .text() — text content
- .html() — inner HTML
- .attr(name) — get/set attribute
- .data(key) — data-* attribute
- .map().get() — convert selection to array
- .filter(fn) — filter selection
- .eq(index) — select by index
- .length — count
```

## Advanced Techniques (Additions)

These advanced techniques extend the existing patterns with production-ready, TypeScript-friendly tips.

### Parsing options & malformed HTML
- Pass options to control parsing:
```ts
const $ = cheerio.load(html, {
  xmlMode: false, // treat input as HTML
  decodeEntities: true, // default: true — decode HTML entities
  normalizeWhitespace: true // collapse whitespace
});
```
- For severely malformed HTML, try htmlparser2 settings or pre-clean the HTML with regex or sanitize-html before loading.

### Preserve indices & map back to source
- Use htmlparser2 parse options if you need node start/end indices (useful for highlighting/exact-source mapping). Cheerio exposes the underlying parser via options—check htmlparser2 docs for withStartIndices.

### xmlMode / fragments
- For parsing fragments or XML feeds (RSS), enable xmlMode:
```ts
const $xml = cheerio.load(xmlString, { xmlMode: true, decodeEntities: false });
```

### Performance & selector optimization
- Cache repeated selections:
```ts
const $items = $('.item');
for (const el of $items.toArray()) {
  const $el = $(el);
  // reuse $el
}
```
- Prefer specific selectors and direct children (.children) where possible.
- Avoid calling costly methods repeatedly (e.g., .text() inside tight loops). Extract once.
- Limit DOM traversal depth and use attribute-based selectors to reduce scan scope.

### Streaming large documents
- For very large HTML, consider streaming parse with htmlparser2 and collect only relevant nodes, then convert fragments to Cheerio before pulling data.

### Decode & maintain entities
- If you need raw HTML entities preserved, set decodeEntities: false and post-process text as needed.

### Sanitize & normalize content
- Use sanitize-html or a similar library to clean dangerous HTML if you plan to store or render scraped content.

### XPath-like access
- Cheerio doesn't natively support XPath. If you need XPath, parse with xmldom and use xpath libraries, or convert XPath to CSS selectors where possible.

### Robust attribute extraction helpers (TypeScript)
- Utility functions help avoid repetitive null checks:
```ts
function attr($el: cheerio.Cheerio, name: string, base?: string) {
  const v = $el.attr(name);
  return v ? (base ? new URL(v, base).href : v) : undefined;
}
function text($el: cheerio.Cheerio) {
  return $el.text().trim().replace(/\s+/g, ' ');
}
function numberFrom($el: cheerio.Cheerio) {
  return parseFloat($el.text().match(/[\d,.]+/)?.[0]?.replace(/,/g, '') ?? '0') || 0;
}
```

### Schema.org, microdata, JSON-LD
- Many sites include structured data. Prefer extracting JSON-LD (`script[type="application/ld+json"]`) or microdata (itemprop) when present — it's less brittle than scraping visible DOM.

### Handling lazy-loaded images & responsive srcsets
- Check multiple sources:
```ts
const src = $img.attr('src') || $img.attr('data-src') || $img.attr('data-lazy') ||
            $img.attr('data-srcset')?.split(',')[0]?.split(' ')[0];
```

### Robust date parsing
- Normalize dates with date-fns or luxon after extracting raw strings. Use multiple formats for parsing.

### Avoiding anti-scraping traps
- Beware of content injected by client-side JS. Cheerio won't run JS — use Playwright for those pages and still prefer Cheerio to parse the final HTML if you need speed.
- Detect common honey-trap patterns like hidden elements with inline CSS display:none or obfuscated timestamps.

### Debugging & selector verification
- Save sample HTML snippets and write unit tests for selectors. Use examples captured in devtools to ensure selectors won't break with small DOM changes.

### Example: utility wrapper (TypeScript)
```ts
import cheerio from 'cheerio';
import got from 'got';

type Extractor<T> = ($: cheerio.Root) => T;

async function fetchAndExtract<T>(url: string, extractor: Extractor<T>) {
  const html = await got(url).text();
  const $ = cheerio.load(html, { decodeEntities: true });
  return extractor($);
}

// usage
const titles = await fetchAndExtract('https://example.com', $ => (
  $('h1').map((i, el) => $(el).text().trim()).get()
));
```

### Combining with got advanced features
- Use got's AbortController, rate-limiting, or caching, then feed HTML into cheerio. Keep a consistent "fetch → sanitize → load → extract → validate" pipeline.

### Validate extracted schemas
- After extracting, validate objects against TypeScript types or JSON schemas to catch subtle extraction errors early.

## Real-World Example: Product Scraper (TypeScript + got + cheerio)

```ts
import got from 'got';
import cheerio from 'cheerio';

interface Product {
  title: string;
  price: string;
  url: string;
  image: string;
}

class ProductScraper {
  private baseUrl = 'https://example-shop.com';
  private client = got.extend({ timeout: { request: 15000 } });

  async scrapeProducts(): Promise<Product[]> {
    const html = await this.client.get(this.baseUrl).text();
    const $ = cheerio.load(html);
    return $('.product-item').map((i, el) => {
      const $p = $(el);
      return {
        title: $p.find('.product-name').text().trim(),
        price: $p.find('.price').text().replace(/[^0-9.]/g, ''),
        url: new URL($p.find('a').attr('href') || '', this.baseUrl).href,
        image: $p.find('img').attr('src') || 'N/A'
      };
    }).get();
  }
}
```

## Multi-Page Scraper with Delays

```ts
async function scrapeMultiplePages(baseUrl: string, maxPages = 5) {
  const items: Array<{ title: string; desc: string; }> = [];
  for (let page = 1; page <= maxPages; page++) {
    const url = `${baseUrl}?page=${page}`;
    console.log(`Scraping ${url}...`);
    const html = await scraper.get(url).text();
    const $ = cheerio.load(html);
    const pageItems = $('.item').map((i, el) => ({
      title: $(el).find('h2').text().trim(),
      desc: $(el).find('p').text().trim()
    })).get();
    if (pageItems.length === 0) break;
    items.push(...pageItems);
    await new Promise(r => setTimeout(r, 2000 + Math.random() * 3000));
  }
  return items;
}
```

## Integration Tips (Got + Cheerio)

- Request HTML with got.get(url).text()
- Use got's timeout and retry options to avoid hangs
- For sites with heavy JS, Cheerio won't run JS — use Playwright/Puppeteer for dynamic pages
- Use cookieJar from got when you need maintained sessions

## Testing Selectors

- Test selectors in browser console first: $$('selector') or document.querySelectorAll()
- Use devtools to inspect DOM structure and attributes
- Use small sample HTML snippets during development

## Best Practices

1. Respect robots.txt & Terms of Service
2. Add random delays and backoff strategies
3. Cache parsed results where useful
4. Avoid scraping personal/private data
5. Handle empty results gracefully
6. Log scraping steps and failures for debugging
7. Prefer descriptive TypeScript interfaces for parsed data
8. Validate and sanitize extracted values (numbers, dates, URLs)
9. Use absolute URLs via new URL(relative, base).href
10. Use headless browsers only when necessary (heavy JS) — they are slower and more detectable

---
Cheerio combined with got is a powerful, lightweight stack for scraping static HTML. For dynamic pages or advanced bot challenges, supplement with a headless browser or an anti-bot solving service.
